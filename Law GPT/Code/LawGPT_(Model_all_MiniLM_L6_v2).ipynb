{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66Tks0GfVf_w",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bd3b34-c148-4aaf-dd8b-713a81cd9155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install Dependencies\n",
        "!pip install transformers PyPDF2\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvs-Nfi5I4tp",
        "outputId": "3f1df59d-b964-46d0-aedc-1e165f4eb7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryk8VzORZnuH"
      },
      "source": [
        "### **Sequence classifier try**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0KbPC3yJuvU",
        "outputId": "da7b986b-fe3c-47af-e561-5b5973bcafff",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers PyPDF2 tqdm numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xuvLVsJ4zndY",
        "outputId": "d31d62db-38dd-410a-b0d2-124b3e0eb03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# Code to create Embeddings**"
      ],
      "metadata": {
        "id": "Mf0kBT6QM1Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JA0jvb3Lxl3N",
        "outputId": "892355ac-bc77-4a96-961e-b235cb2e7214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/227.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load pre-trained SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to load IPC chunks from a pickle file\n",
        "def load_chunks(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Function to generate embeddings using SentenceTransformer\n",
        "def generate_embeddings(chunks):\n",
        "    embeddings = []\n",
        "    for chunk in tqdm(chunks, desc=\"Generating embeddings\"):\n",
        "        embedding = model.encode(chunk, convert_to_tensor=True).cpu().numpy()\n",
        "        embeddings.append(embedding)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Main function to process the IPC document and save embeddings\n",
        "def process_ipc(file_path, output_file):\n",
        "    # Load IPC chunks\n",
        "    ipc_chunks = load_chunks(file_path)\n",
        "\n",
        "    # Generate embeddings for the chunks\n",
        "    embeddings = generate_embeddings(ipc_chunks)\n",
        "\n",
        "    # Save embeddings to a pickle file\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(embeddings, f)\n",
        "\n",
        "    print(f\"Embeddings saved to {output_file}\")\n",
        "\n",
        "# Example usage: Process IPC document and save embeddings\n",
        "process_ipc('/content/ipc_chunks_all.pkl', 'ipc_embeddings_st.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjZ-ZTHOv9O5",
        "outputId": "e2d8cfa1-aef9-45b6-932f-764471c806ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|██████████| 2369/2369 [02:24<00:00, 16.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved to ipc_embeddings_st.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code to create Chunks**"
      ],
      "metadata": {
        "id": "zuBtt2suT2oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Function to read the IPC PDF and extract text\n",
        "def load_ipc_pdf(file_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        reader = PdfReader(file_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF file: {e}\")\n",
        "    return text\n",
        "\n",
        "# Function to split text into manageable chunks\n",
        "def split_text(text, max_chunk_size=512, min_chunk_size=256):\n",
        "    # Split at sentence boundaries while respecting chunk size constraints\n",
        "    sentences = re.split(r'(?<=\\.)\\s', text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
        "            current_chunk += sentence + \" \"\n",
        "            # Ensure minimum chunk size is maintained\n",
        "            if len(current_chunk) >= min_chunk_size:\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = \"\"\n",
        "        else:\n",
        "            # If the current sentence exceeds max_chunk_size, split it forcibly\n",
        "            while len(sentence) > max_chunk_size:\n",
        "                chunks.append(sentence[:max_chunk_size].strip())\n",
        "                sentence = sentence[max_chunk_size:]\n",
        "            current_chunk = sentence + \" \"\n",
        "\n",
        "    # Append the remaining chunk if it meets the minimum size\n",
        "    if len(current_chunk) >= min_chunk_size:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Main function to process the IPC documents in a folder and save chunks to a single pickle file\n",
        "def process_ipc_folder(folder_path, output_file):\n",
        "    all_chunks = []\n",
        "\n",
        "    # Iterate through all PDF files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing file: {file_path}\")\n",
        "            # Load the IPC text and split into chunks\n",
        "            ipc_text = load_ipc_pdf(file_path)\n",
        "            ipc_chunks = split_text(ipc_text)\n",
        "            all_chunks.extend(ipc_chunks)\n",
        "\n",
        "    # Save all chunks to a pickle file\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(all_chunks, f)\n",
        "\n",
        "# Example usage: Process all PDFs in '/content/Dataset' and save to 'ipc_chunks_all.pkl'\n",
        "process_ipc_folder('/content/Dataset', '/content/ipc_chunks_all.pkl')\n"
      ],
      "metadata": {
        "id": "dQ2EaHw5TlQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32f765c-7ea8-46ce-e817-eec85c211417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/Dataset/IPC_186045.pdf\n",
            "Processing file: /content/Dataset/A1860-45.pdf\n",
            "Processing file: /content/Dataset/1360312590693-12.Cyber-Laws-chapter-in-Legal-Aspects-Book.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using MiniLM-L6-V2 model**"
      ],
      "metadata": {
        "id": "K7dVeJ5zy4W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load pre-trained SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to load chunks from a pickle file\n",
        "def load_chunks(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Function to calculate weighted query embedding\n",
        "def calculate_weighted_query_embedding(roberta_output):\n",
        "    embeddings = []\n",
        "    weights = []\n",
        "    for keyword, weight in roberta_output:\n",
        "        embedding = model.encode(keyword, convert_to_tensor=True).cpu().numpy()\n",
        "        embeddings.append(embedding)\n",
        "        weights.append(weight)\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    weights = np.array(weights).reshape(-1, 1)\n",
        "    weighted_embedding = np.sum(embeddings * weights, axis=0) / np.sum(weights)\n",
        "    return weighted_embedding\n",
        "\n",
        "# Main function to process the IPC document\n",
        "def process_ipc():\n",
        "    try:\n",
        "        # Load preprocessed chunks and embeddings\n",
        "        ipc_chunks = load_chunks('/content/ipc_chunks_all.pkl')\n",
        "        ipc_embeddings = load_chunks('/content/ipc_embeddings_st.pkl')\n",
        "        ipc_embeddings = np.vstack(ipc_embeddings)  # Ensure embeddings are a NumPy array\n",
        "    except (FileNotFoundError, EOFError):\n",
        "        print(\"Preprocessed chunks or embeddings not found. Please ensure the files exist.\")\n",
        "        return\n",
        "\n",
        "    # Initialize FAISS index\n",
        "    dimension = ipc_embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(ipc_embeddings.astype('float32'))  # Ensure ipc_embeddings are float32\n",
        "\n",
        "    # Example input from the RoBERTa model\n",
        "    roberta_output = [('67', 0.8539), ('ipc', 0.7163), ('section', 0.6221)]\n",
        "    query_embedding = calculate_weighted_query_embedding(roberta_output)\n",
        "\n",
        "    # Ensure the query_embedding has the same dimension as the FAISS index\n",
        "    assert query_embedding.shape[0] == dimension, f\"Dimension mismatch: query ({query_embedding.shape[0]}) vs index ({dimension})\"\n",
        "\n",
        "    # Search in FAISS index\n",
        "    k = 5  # Number of top results to retrieve\n",
        "    query_embedding = query_embedding.reshape(1, -1).astype('float32')  # Ensure query_embedding is float32\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Prepare and return results\n",
        "    results = []\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        result = {\n",
        "            \"distance\": distances[0][i],\n",
        "            \"text\": ipc_chunks[idx]\n",
        "        }\n",
        "        results.append(result)\n",
        "        print(f\"Result {i+1}:\")\n",
        "        print(f\"Distance: {result['distance']:.4f}\")\n",
        "        print(f\"Text: {result['text']}\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the main processing function\n",
        "process_ipc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynjpvcNQy3-i",
        "outputId": "2224a5e4-a1d2-442b-fb99-f13552aafde4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result 1:\n",
            "Distance: 0.9334\n",
            "Text: Section 67-A deals with publishing or transmitting of material containi ng sexually explicit act in \n",
            "electronic form.  Contents of Section 67 when combined with  the material containing sexually explicit \n",
            "material attract penalty under this Section. \n",
            "Child Pornography  has been exclusively dealt with under Section 67B.\n",
            "\n",
            "Result 2:\n",
            "Distance: 0.9588\n",
            "Text: Section 69A inserted in the ITAA, vests with the Centra l Government or any of its officers \n",
            "with the powers to issue directions for blocking for publi c access of any information through \n",
            "any computer resource, under the same circumstances as me ntioned above.\n",
            "\n",
            "Result 3:\n",
            "Distance: 0.9891\n",
            "Text: 376C.  Sexual intercourse by a person in authority.  \n",
            "376D.  Gang rape . \n",
            "376E. Punishment for repeat offenders.  \n",
            "Of Unnatural offences  \n",
            "377. Unnatural offences.  \n",
            " \n",
            "CHAPTER XVII  \n",
            "OF OFFENCES AGAINST PROPERTY  \n",
            "Of Theft  \n",
            "378. Theft.  \n",
            "379. Punishment for theft.\n",
            "\n",
            "Result 4:\n",
            "Distance: 0.9924\n",
            "Text: Ins. by Act 43 of 1983, s. 2.  \n",
            "2. Subs. by Act 13 of 2013, s. 4, for “offence under section 376, section 376A, section 376B, section  376C or section 376D” \n",
            "(w.e.f. 3 -2-2013 ). \n",
            "3. Subs. by Act 22 of 2018, s. 3, for “ section 376A, section 376B, section 376C, section 376D ” (w.e.f.\n",
            "\n",
            "Result 5:\n",
            "Distance: 1.0168\n",
            "Text: 1. Ins. by Act 13 of 2013, s. 3 (w.e .f. 03 -02-2013).  \n",
            "2. Subs. by Act 22 of 2018, s. 2, for “ section 3 76B, section 376C, section 376D” (w.e.f. 21 -4-2018).    \n",
            "3. Subs. by Act 21 of 2000, s.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'distance': 0.93342936,\n",
              "  'text': 'Section 67-A deals with publishing or transmitting of material containi ng sexually explicit act in \\nelectronic form.  Contents of Section 67 when combined with  the material containing sexually explicit \\nmaterial attract penalty under this Section. \\nChild Pornography  has been exclusively dealt with under Section 67B.'},\n",
              " {'distance': 0.95875084,\n",
              "  'text': 'Section 69A inserted in the ITAA, vests with the Centra l Government or any of its officers \\nwith the powers to issue directions for blocking for publi c access of any information through \\nany computer resource, under the same circumstances as me ntioned above.'},\n",
              " {'distance': 0.98911446,\n",
              "  'text': '376C.  Sexual intercourse by a person in authority.  \\n376D.  Gang rape . \\n376E. Punishment for repeat offenders.  \\nOf Unnatural offences  \\n377. Unnatural offences.  \\n \\nCHAPTER XVII  \\nOF OFFENCES AGAINST PROPERTY  \\nOf Theft  \\n378. Theft.  \\n379. Punishment for theft.'},\n",
              " {'distance': 0.99239975,\n",
              "  'text': 'Ins. by Act 43 of 1983, s. 2.  \\n2. Subs. by Act 13 of 2013, s. 4, for “offence under section 376, section 376A, section 376B, section  376C or section 376D” \\n(w.e.f. 3 -2-2013 ). \\n3. Subs. by Act 22 of 2018, s. 3, for “ section 376A, section 376B, section 376C, section 376D ” (w.e.f.'},\n",
              " {'distance': 1.0167576,\n",
              "  'text': '1. Ins. by Act 13 of 2013, s. 3 (w.e .f. 03 -02-2013).  \\n2. Subs. by Act 22 of 2018, s. 2, for “ section 3 76B, section 376C, section 376D” (w.e.f. 21 -4-2018).    \\n3. Subs. by Act 21 of 2000, s.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time **Report**"
      ],
      "metadata": {
        "id": "LJz6ECQlIn4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GQ_o3NGTIuIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Start the timer\n",
        "start = time.time()\n",
        "\n",
        "# Code to measure\n",
        "# Example function or process\n",
        "def example_process():\n",
        "    time.sleep(2)  # Simulate a process that takes 2 seconds\n",
        "\n",
        "example_process()\n",
        "\n",
        "# End the timer\n",
        "end = time.time()\n",
        "\n",
        "# Print the elapsed time\n",
        "print(\"Time taken: \", end - start, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4l-h-ODImO_",
        "outputId": "2c8c9975-30b2-4086-b03d-c268f86f1dfd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken:  2.002437114715576 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FineTuning on IPC **CodeBook (Pending)**"
      ],
      "metadata": {
        "id": "dxKwaY0-LUXj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}