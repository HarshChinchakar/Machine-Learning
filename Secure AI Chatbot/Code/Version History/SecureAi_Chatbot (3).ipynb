{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFmyMcpUTOya"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuAhgVGrTq5z"
      },
      "source": [
        "# **Assumed input from UI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NXgdOp8MSxD"
      },
      "outputs": [],
      "source": [
        "# Query = \"What are some good tips for staying productive while working from home?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UM6YPikTl9Y"
      },
      "source": [
        "# **AES Encryption**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wVjHdsgWLcH"
      },
      "source": [
        "This code securely encrypts and decrypts data using AES encryption in GCM mode, which includes an authentication tag to validate the integrity and authenticity of the encrypted data. It also derives a strong cryptographic key from a password and salt, ensuring secure key management and protection against unauthorized access in the chatbox application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-kgVPRNTwdO"
      },
      "source": [
        "key generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqfr5DjcTveZ",
        "outputId": "0a530ee9-b858-4f6b-c3ce-b89dd19d9d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key : b\"\\xb7\\xc1\\x8b\\xe2'\\xb1\\x82\\xd9\\xdb\\xec\\xccV\\tx\\xfc\\x19\\x0f/\\x18\\xe5a\\x10\\x0e\\xbf|e\\xfa\\x08\\x80\\xd6\\xa3\\x90\"\n"
          ]
        }
      ],
      "source": [
        "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
        "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "from cryptography.hazmat.primitives import padding\n",
        "import os\n",
        "import base64\n",
        "\n",
        "# Function to generate a key from a password\n",
        "def generate_key(password, salt):\n",
        "    kdf = PBKDF2HMAC(\n",
        "        algorithm=hashes.SHA256(),\n",
        "        length=32,\n",
        "        salt=salt,\n",
        "        iterations=100000,\n",
        "        backend=default_backend()\n",
        "    )\n",
        "    key = kdf.derive(password.encode())\n",
        "    return key\n",
        "\n",
        "# Encryption function\n",
        "def encrypt_data(plaintext, key):\n",
        "    iv = os.urandom(16)\n",
        "    cipher = Cipher(algorithms.AES(key), modes.GCM(iv), backend=default_backend())\n",
        "    encryptor = cipher.encryptor()\n",
        "    padder = padding.PKCS7(128).padder()\n",
        "    padded_data = padder.update(plaintext.encode()) + padder.finalize()\n",
        "    ciphertext = encryptor.update(padded_data) + encryptor.finalize()\n",
        "    tag = encryptor.tag  # Get the authentication tag\n",
        "    return base64.b64encode(iv + tag + ciphertext).decode()\n",
        "\n",
        "# Decryption function\n",
        "def decrypt_data(ciphertext, key):\n",
        "    data = base64.b64decode(ciphertext)\n",
        "    iv = data[:16]\n",
        "    tag = data[16:32]\n",
        "    cipher = Cipher(algorithms.AES(key), modes.GCM(iv, tag), backend=default_backend())\n",
        "    decryptor = cipher.decryptor()\n",
        "    plaintext_padded = decryptor.update(data[32:]) + decryptor.finalize()  # Start after the tag\n",
        "    unpadder = padding.PKCS7(128).unpadder()\n",
        "    plaintext = unpadder.update(plaintext_padded) + unpadder.finalize()\n",
        "    return plaintext.decode()\n",
        "\n",
        "#Key- generation\n",
        "password = \"SecureAIChatbot\"\n",
        "salt = os.urandom(16)\n",
        "key = generate_key(password, salt)\n",
        "print('key :',key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9iHaOBCUhBi"
      },
      "source": [
        "Encryption dry-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V4Td6cuUgch",
        "outputId": "d85e749e-8ae1-487b-e70a-ec8f69a20ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RS/WW7J59jSu7ee+ZYsSv11Pzf0cabF87hnArsHaLvtOvpOaYt4c4jyWi03Wb41f5K/IbJ9XZ0SkxzxL1dsUK9Ka6Tj4FnIAFDMT66G44QCVZslfeN0oa47HxMtxe7ZpOC11Kk53z2mRVetGXEyX9A==\n"
          ]
        }
      ],
      "source": [
        "# Encrypt the query\n",
        "encrypted_query = encrypt_data(Query, key)\n",
        "print(encrypted_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze1z-KyAUutx",
        "outputId": "27d254c5-da50-46c1-d1a8-515fd898de60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What are some good tips for staying productive while working from home?\n"
          ]
        }
      ],
      "source": [
        "# Decrypt the query\n",
        "decrypted_query = decrypt_data(encrypted_query, key)\n",
        "print(decrypted_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMDDyXQ0YEg-"
      },
      "source": [
        "# **Adversarial attack checks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "JJDwX7EilWxd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def detect_adversarial_attack(query):\n",
        "    \"\"\"\n",
        "    Detects simple adversarial attacks in the input query.\n",
        "    Focuses on common patterns used in prompt injection and other attack techniques.\n",
        "    \"\"\"\n",
        "\n",
        "    # Common patterns used in prompt injections and other attacks\n",
        "    adversarial_patterns = [\n",
        "        r\"^.*\\bshutdown\\b.*$\",  # Command injections\n",
        "        r\"^.*\\bdelete\\b.*$\",    # Malicious commands\n",
        "        r\"^.*\\bignore\\b.*$\",    # Instructions to bypass logic\n",
        "        r\"^.*\\bmodify\\b.*$\",    # Instructions to change behavior\n",
        "        r\"^.*\\bself-destruct\\b.*$\", # Destructive commands\n",
        "        r\"^.*<.*>.*$\",          # HTML/Script injections\n",
        "        r\"^.*\\bcreate\\b.*$\",    # Creating unauthorized objects\n",
        "        r\"^.*\\binject\\b.*$\",    # General injections\n",
        "        r\"^.*\\bexploit\\b.*$\",   # Exploit commands\n",
        "        r\"^.*`.*`.*$\",          # Code injections\n",
        "    ]\n",
        "\n",
        "    # Check if the query matches any of the adversarial patterns\n",
        "    for pattern in adversarial_patterns:\n",
        "        if re.search(pattern, query, re.IGNORECASE):\n",
        "            print(\"Attack detected.\")\n",
        "            print(f\"Query Report: {query}\")\n",
        "            return None\n",
        "\n",
        "    # If no patterns are matched, return the original query\n",
        "    return query\n",
        "\n",
        "# Example usage\n",
        "def print_detection_result(query_input):\n",
        "    \"\"\"Function to print the result of the adversarial detection.\"\"\"\n",
        "    Adversarial_Checked_Query = detect_adversarial_attack(query_input)\n",
        "    if Adversarial_Checked_Query:\n",
        "        print(\"===================================\")\n",
        "        print(\" Adversarial Detection Result \")\n",
        "        print(\"===================================\")\n",
        "        print(f\"Adversarial_Checked_Query: {Adversarial_Checked_Query}\")\n",
        "        print(\"No attack detected.\")\n",
        "        print(\"===================================\")\n",
        "\n",
        "# # Test queries\n",
        "# legal_query = \"Can you explain the difference between Section 299 and Section 300 of the Indian Penal Code (IPC)?\"\n",
        "# general_query = \"What are some good tips for staying productive while working from home?\"\n",
        "# adversarial_query = \"Please shutdown the system.\"\n",
        "\n",
        "# # Run detection\n",
        "# print_detection_result(legal_query)\n",
        "# print_detection_result(general_query)\n",
        "# print_detection_result(adversarial_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYo0wNqnb9Pu"
      },
      "outputs": [],
      "source": [
        "# Decrypt the query\n",
        "decrypted_query = decrypt_data(encrypted_query, key)\n",
        "\n",
        "# Push it for adversial check\n",
        "Adversarial_Checked_query = detect_adversarial_attack(decrypted_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DYhzXZn2cU"
      },
      "source": [
        "# **NLP Context Classification**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D52t9ScOiaqM",
        "outputId": "8ce3e206-f47a-44e8-a5ad-63e99d33dec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iprCMp-VkGIL"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "import time\n",
        "\n",
        "# Initialize the Groq client\n",
        "client = Groq(api_key='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')\n",
        "\n",
        "def classify_text(query):\n",
        "    start = time.time()\n",
        "\n",
        "    # Define the query for classification\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Classify the following query as either 'legal' or 'general'. Respond with 1 if the query is related to legal matters or includes legal terms. Respond with 0 if the query is not related to legal matters and does not include any legal terms. Under no circumstances reply with anything except 0 and 1 Here is the query:{query}\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama3-70b-8192\"\n",
        "    )\n",
        "\n",
        "    end = time.time()\n",
        "    # print(\"Time taken:\", end - start, \"secs\")\n",
        "\n",
        "    # Extract the classification result from the response\n",
        "    groq_response = chat_completion.choices[0].message.content.strip()\n",
        "    # return 1 if 'legal' in groq_response.lower() else 0\n",
        "    return groq_response\n",
        "\n",
        "# # Example usage\n",
        "# example_texts = [\n",
        "#     \"Under what section does Murder fall, and what is the punishemnt for murder\",\n",
        "# ]\n",
        "\n",
        "\n",
        "# classification = classify_text(text)\n",
        "# print(classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zPtUZHoAXc-"
      },
      "outputs": [],
      "source": [
        "dummy_Query = \"How do I calculate the ROI on a real estate investment?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H9zPzNSxmb4",
        "outputId": "d647edc0-5bcb-4396-ddb0-30beb44d432b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "How do I calculate the ROI on a real estate investment?\n"
          ]
        }
      ],
      "source": [
        "Query_Classification = classify_text(dummy_Query)\n",
        "print(Query_Classification)\n",
        "print(dummy_Query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao575lhTsGiO"
      },
      "source": [
        "# **Content Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "I5ehLzQysNXD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Replace with your actual Perspective API key\n",
        "PERSPECTIVE_API_KEY = 'AIzaSyDBLq0UyuPedruRMgiR_r5uRqbCh57gFeA'\n",
        "\n",
        "# Load the list of words to bypass from a file\n",
        "def load_bypass_words(file_path='/content/unique_words.txt'):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return set(line.strip() for line in file)\n",
        "\n",
        "bypass_words = load_bypass_words()\n",
        "\n",
        "# Function to get moderation scores from Perspective API for a single word\n",
        "def moderate_word(word):\n",
        "    url = f'https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key={PERSPECTIVE_API_KEY}'\n",
        "    data = {\n",
        "        \"comment\": {\"text\": word},\n",
        "        \"languages\": [\"en\"],\n",
        "        \"requestedAttributes\": {\"TOXICITY\": {}, \"INSULT\": {}, \"PROFANITY\": {}},\n",
        "        \"doNotStore\": True\n",
        "    }\n",
        "    response = requests.post(url, json=data)\n",
        "    return response.json()\n",
        "\n",
        "# Main filtering function\n",
        "def filter_content(Context_01, Adversarial_Checked_query):\n",
        "    threshold = 0.5\n",
        "    words = Adversarial_Checked_query.split()\n",
        "    filtered_words = []\n",
        "    removed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        # If in legal context (Context_01 == 1), check for bypass words\n",
        "        if Context_01 == 1 and word in bypass_words:\n",
        "            filtered_words.append(word)\n",
        "            continue\n",
        "\n",
        "        # Get moderation scores\n",
        "        moderation_scores = moderate_word(word)\n",
        "\n",
        "        # Check if 'attributeScores' is in the response\n",
        "        if 'attributeScores' in moderation_scores:\n",
        "            if not any(\n",
        "                moderation_scores['attributeScores'][attr]['summaryScore']['value'] > threshold\n",
        "                for attr in ['TOXICITY', 'INSULT', 'PROFANITY']\n",
        "            ):\n",
        "                filtered_words.append(word)\n",
        "            else:\n",
        "                removed_words.append(word)\n",
        "        else:\n",
        "            # Handle cases where the response does not contain 'attributeScores'\n",
        "            filtered_words.append(word)\n",
        "\n",
        "    # Join the filtered words to form the final filtered text\n",
        "    filtered_text = ' '.join(filtered_words)\n",
        "    return filtered_text\n",
        "\n",
        "# # Example usage\n",
        "# Context_01 = 0  # General context\n",
        "# Adversarial_Checked_query = \"You are so stupid and worthless, no one cares about anything you say.\"\n",
        "\n",
        "# filtered_text, removed_words = filter_content(Context_01, Adversarial_Checked_query)\n",
        "\n",
        "# print(\"Filtered Text:\", filtered_text)\n",
        "# print(\"Removed Words:\", removed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQB2lbqvYJua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "10dbdb3a-0d61-4b61-9343-bab7b2eff31f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Query_Classification' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ae50ec30461e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mContent_filtered_Query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuery_Classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdversarial_Checked_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Query_Classification' is not defined"
          ]
        }
      ],
      "source": [
        "Content_filtered_Query = filter_content(Query_Classification, Adversarial_Checked_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyV4-dopYXqZ",
        "outputId": "ae53bfc9-147f-417a-99c4-d43eeb31a055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What are some good tips for staying productive while working from home?\n"
          ]
        }
      ],
      "source": [
        "print(Content_filtered_Query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyLVdYWosNuI"
      },
      "source": [
        "# **LLM Guard**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWABh0iyt6Ha"
      },
      "source": [
        "To be implemented in a pseudo environment for successful implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IA_SWhK6sRh6",
        "outputId": "4768e8b1-5f1b-4e19-ac7f-a66133c72952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llm-guard\n",
            "  Downloading llm_guard-0.3.15-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bc-detect-secrets==1.5.15 (from llm-guard)\n",
            "  Downloading bc_detect_secrets-1.5.15-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting faker<28,>=26.0.0 (from llm-guard)\n",
            "  Downloading Faker-27.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting fuzzysearch<0.9,>=0.7 (from llm-guard)\n",
            "  Downloading fuzzysearch-0.7.3.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting json-repair<0.29,>=0.25.2 (from llm-guard)\n",
            "  Downloading json_repair-0.28.4-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting nltk<4,>=3.9.1 (from llm-guard)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting presidio-analyzer==2.2.354 (from llm-guard)\n",
            "  Downloading presidio_analyzer-2.2.354-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting presidio-anonymizer==2.2.354 (from llm-guard)\n",
            "  Downloading presidio_anonymizer-2.2.354-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting regex==2024.7.24 (from llm-guard)\n",
            "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<0.8,>=0.5 (from llm-guard)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from llm-guard) (2.4.0+cu121)\n",
            "Collecting transformers>=4.43.4 (from llm-guard)\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting structlog>=24 (from llm-guard)\n",
            "  Downloading structlog-24.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting oldest-supported-numpy (from llm-guard)\n",
            "  Downloading oldest_supported_numpy-2023.12.21-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from bc-detect-secrets==1.5.15->llm-guard) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bc-detect-secrets==1.5.15->llm-guard) (2.32.3)\n",
            "Collecting unidiff (from bc-detect-secrets==1.5.15->llm-guard)\n",
            "  Downloading unidiff-0.7.5-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer==2.2.354->llm-guard) (3.7.6)\n",
            "Collecting tldextract (from presidio-analyzer==2.2.354->llm-guard)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer==2.2.354->llm-guard)\n",
            "  Downloading phonenumbers-8.13.44-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio-anonymizer==2.2.354->llm-guard)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker<28,>=26.0.0->llm-guard) (2.8.2)\n",
            "Requirement already satisfied: attrs>=19.3 in /usr/local/lib/python3.10/dist-packages (from fuzzysearch<0.9,>=0.7->llm-guard) (24.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4,>=3.9.1->llm-guard) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4,>=3.9.1->llm-guard) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4,>=3.9.1->llm-guard) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->llm-guard) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.4->llm-guard) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.4->llm-guard) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.4->llm-guard) (24.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.4->llm-guard) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.4->llm-guard) (0.19.1)\n",
            "Collecting numpy>=1.17 (from transformers>=4.43.4->llm-guard)\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker<28,>=26.0.0->llm-guard) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bc-detect-secrets==1.5.15->llm-guard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bc-detect-secrets==1.5.15->llm-guard) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bc-detect-secrets==1.5.15->llm-guard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bc-detect-secrets==1.5.15->llm-guard) (2024.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.12.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (71.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->llm-guard) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->llm-guard) (1.3.0)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer==2.2.354->llm-guard)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.20.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (7.0.4)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm-guard) (0.1.2)\n",
            "Downloading llm_guard-0.3.15-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bc_detect_secrets-1.5.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.6/119.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_analyzer-2.2.354-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.354-py3-none-any.whl (31 kB)\n",
            "Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Faker-27.4.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.28.4-py3-none-any.whl (13 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-24.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oldest_supported_numpy-2023.12.21-py3-none-any.whl (4.9 kB)\n",
            "Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.44-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unidiff-0.7.5-py2.py3-none-any.whl (14 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: fuzzysearch\n",
            "  Building wheel for fuzzysearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fuzzysearch: filename=fuzzysearch-0.7.3-cp310-cp310-linux_x86_64.whl size=293924 sha256=5f8044dc7c9943b933aa34097968bccc8a8b23a59dcfe191b10546fc92a7acfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/fb/bf/1c4f359d4b13bbc0e2cef8703d8a7c10dcd1e377496c19e6dc\n",
            "Successfully built fuzzysearch\n",
            "Installing collected packages: unidiff, phonenumbers, structlog, regex, pycryptodome, numpy, json-repair, fuzzysearch, tiktoken, requests-file, presidio-anonymizer, oldest-supported-numpy, nltk, faker, bc-detect-secrets, tldextract, transformers, presidio-analyzer, llm-guard\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.5.15\n",
            "    Uninstalling regex-2024.5.15:\n",
            "      Successfully uninstalled regex-2024.5.15\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.21.6 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "flax 0.8.4 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "geopandas 0.14.4 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "jax 0.4.26 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "jaxlib 0.4.26+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "pandas 2.1.4 requires numpy<2,>=1.22.4; python_version < \"3.11\", but you have numpy 1.21.6 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.21.6 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 1.21.6 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.21.6 which is incompatible.\n",
            "tensorstore 0.1.64 requires numpy>=1.22.0, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray-einstats 0.7.0 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bc-detect-secrets-1.5.15 faker-27.4.0 fuzzysearch-0.7.3 json-repair-0.28.4 llm-guard-0.3.15 nltk-3.9.1 numpy-1.21.6 oldest-supported-numpy-2023.12.21 phonenumbers-8.13.44 presidio-analyzer-2.2.354 presidio-anonymizer-2.2.354 pycryptodome-3.20.0 regex-2024.7.24 requests-file-2.1.0 structlog-24.4.0 tiktoken-0.7.0 tldextract-5.1.2 transformers-4.44.2 unidiff-0.7.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b07799b9b1d34142bcbab19243cb80c9",
              "pip_warning": {
                "packages": [
                  "nltk",
                  "numpy",
                  "regex",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install llm-guard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU3BfWARsq2Z"
      },
      "outputs": [],
      "source": [
        "from llm_guard import LLMGuard\n",
        "\n",
        "# Initialize the LLM Guard model (use an appropriate configuration)\n",
        "llm_guard = LLMGuard(model_name=\"llm-guard/safe-guard\", threshold=0.5)\n",
        "\n",
        "def check_query_safety(query):\n",
        "    \"\"\"\n",
        "    Function to check the safety of the query using LLM Guard.\n",
        "    Returns the query if deemed safe, otherwise raises an exception.\n",
        "\n",
        "    Args:\n",
        "    query (str): The input query to check.\n",
        "\n",
        "    Returns:\n",
        "    str: The original query if it passes all safety checks.\n",
        "\n",
        "    Raises:\n",
        "    Exception: If the query is found to be unsafe.\n",
        "    \"\"\"\n",
        "    # Check the query using LLM Guard\n",
        "    safety_score, is_safe = llm_guard.check(query)\n",
        "\n",
        "    # If the query is deemed safe, return it\n",
        "    if is_safe:\n",
        "        return query\n",
        "\n",
        "    # If the query is not safe, raise an exception\n",
        "    raise Exception(\"Attack detected: Query flagged as unsafe by LLM Guard.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqUFXCvUs95V"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "try:\n",
        "    safe_query = check_query_safety(Query)\n",
        "    print(\"Query passed all checks:\", safe_query)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqF70zBsuEWY"
      },
      "source": [
        "# **NLP Processing**\n",
        "This function takes the query as input and processes it ad gives the keywords with respective weights and overall sentiment affiliated with it. They keywords are stored in \"NLP_Keywords\" tuple, and sentiment is stored in a Global variable \"global_sentiment_score\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WxqVDnadyYEG",
        "outputId": "620d7cd3-e7c5-47cd-9ab7-e43779577449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KeyBERT\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from KeyBERT) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from KeyBERT) (13.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from KeyBERT) (1.3.2)\n",
            "Collecting sentence-transformers>=0.3.8 (from KeyBERT)\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->KeyBERT) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->KeyBERT) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->KeyBERT) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->KeyBERT) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->KeyBERT) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->KeyBERT) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->KeyBERT) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->KeyBERT) (2.4.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->KeyBERT) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->KeyBERT) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->KeyBERT) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->KeyBERT) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->KeyBERT) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->KeyBERT) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->KeyBERT) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->KeyBERT) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->KeyBERT) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->KeyBERT) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->KeyBERT) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->KeyBERT) (1.3.0)\n",
            "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers, KeyBERT\n",
            "Successfully installed KeyBERT-0.8.5 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install KeyBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rl6JO_zjuWV_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from keybert import KeyBERT\n",
        "\n",
        "# Global variable to store sentiment score\n",
        "global_sentiment_score = None\n",
        "\n",
        "def extract_keywords(query):\n",
        "    # Initialize the KeyBERT model\n",
        "    model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "    # Extract keywords\n",
        "    keywords = model.extract_keywords(query)\n",
        "\n",
        "    return keywords\n",
        "\n",
        "def get_sentiment(text, sentiment_pipeline):\n",
        "    result = sentiment_pipeline(text)[0]\n",
        "    label = result['label']\n",
        "    score = result['score']\n",
        "\n",
        "    if label == 'POSITIVE':\n",
        "        return \"Positive\", score\n",
        "    else:\n",
        "        return \"Negative\", 1 - score\n",
        "\n",
        "def process_query(Adversarial_Checked_Query):\n",
        "    global global_sentiment_score\n",
        "\n",
        "    # Sentiment analysis using DistilBERT fine-tuned on SST-2\n",
        "    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    # Extract keywords\n",
        "    keywords = extract_keywords(Adversarial_Checked_Query)\n",
        "\n",
        "    # Analyze sentiment\n",
        "    sentiment, sentiment_score = get_sentiment(Adversarial_Checked_Query, sentiment_pipeline)\n",
        "\n",
        "    # Store sentiment score globally\n",
        "    global_sentiment_score = sentiment_score\n",
        "    return keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lapThOr64AgS"
      },
      "outputs": [],
      "source": [
        "# Adversarial_Checked_Query = \"Could you please inform me about the specific section of the (IPC) under which an individual could be charged for murder, or attempt to murder\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QQ-wE0PT4ARp",
        "outputId": "91027342-94b5-4b18-8753-13c073e0bc0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('home', 0.4764), ('working', 0.4574), ('productive', 0.3846), ('tips', 0.3822), ('staying', 0.3181)]\n"
          ]
        }
      ],
      "source": [
        "# Process the query and store the results\n",
        "NLP_Keywords = process_query(Content_filtered_Query)\n",
        "print(NLP_Keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PW6P_FMuW6n"
      },
      "source": [
        "# **Query Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVkxfu51ubOQ"
      },
      "source": [
        "## **LawGPT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxRpcKwLMAfS"
      },
      "outputs": [],
      "source": [
        "#Dummy Input\n",
        "# Adversarial_Checked_query = \"Could you please inform me about the specific section of the (IPC) under which an individual could be charged for murder, or attempt to murder\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsgy2BOpMAKK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HUI1GnIcuao4",
        "outputId": "6f003c66-df21-4dce-c472-ebc0e4c40134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.8)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: PyPDF2, jedi\n",
            "Successfully installed PyPDF2-3.0.1 jedi-0.19.1\n",
            "Requirement already satisfied: keybert in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.3.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.4.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers torch ipywidgets PyPDF2 tqdm numpy\n",
        "\n",
        "#Installation\n",
        "!pip install keybert\n",
        "\n",
        "!pip install faiss-gpu\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# Groq installation\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nRjRInc1uaMo",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from PyPDF2 import PdfReader\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "from keybert import KeyBERT\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from PyPDF2 import PdfReader\n",
        "import pickle\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import time\n",
        "\n",
        "from groq import Groq\n",
        "# Initializing client\n",
        "client = Groq(\n",
        "  api_key = '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',\n",
        ")\n",
        "\n",
        "import pickle\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load pre-trained SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def list_of_dicts_to_string(top_results):\n",
        "    # Convert list of dictionaries to a string format\n",
        "    result_string = '\\n\\n'.join('\\n'.join(f\"{key}: {value}\" for key, value in result.items()) for result in top_results)\n",
        "    return result_string\n",
        "\n",
        "def load_chunks(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        # print(f\"Loaded {len(data)} chunks from {file_path}\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading chunks from {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to calculate weighted query embedding\n",
        "def calculate_weighted_query_embedding(roberta_output):\n",
        "    embeddings = []\n",
        "    weights = []\n",
        "\n",
        "    if not roberta_output:\n",
        "        # print(\"Error: roberta_output is empty.\")\n",
        "        return np.zeros(384)  # Return a zero vector of dimension 384 as a placeholder\n",
        "\n",
        "    for keyword, weight in roberta_output:\n",
        "        # print(f\"Keyword: {keyword}, Weight: {weight}\")  # Print for debugging\n",
        "        embedding = model.encode(keyword, convert_to_tensor=True).cpu().numpy()\n",
        "        embeddings.append(embedding)\n",
        "        weights.append(weight)\n",
        "\n",
        "    embeddings = np.array(embeddings)  # Convert list of embeddings to numpy array\n",
        "    weights = np.array(weights).reshape(-1, 1)  # Convert weights to numpy array\n",
        "\n",
        "    if len(embeddings) == 0:\n",
        "        # print(\"Error: No embeddings calculated.\")\n",
        "        return np.zeros(384)  # Return a zero vector of dimension 384 as a placeholder\n",
        "\n",
        "    # Calculate weighted average embedding\n",
        "    weighted_embedding = np.sum(embeddings * weights, axis=0) / np.sum(weights)\n",
        "\n",
        "    return weighted_embedding\n",
        "\n",
        "# Main function to process the IPC document\n",
        "def process_ipc(roberta_output):\n",
        "    try:\n",
        "        # Load preprocessed chunks and embeddings\n",
        "        ipc_chunks = load_chunks('/content/ipc_chunks_all_828.pkl')\n",
        "        ipc_embeddings = load_chunks('/content/chunks_embeddings_828.pkl')\n",
        "        ipc_embeddings = np.vstack(ipc_embeddings)  # Ensure embeddings are a NumPy array\n",
        "    except (FileNotFoundError, EOFError):\n",
        "        # print(\"Preprocessed chunks or embeddings not found. Please ensure the files exist.\")\n",
        "        return\n",
        "\n",
        "    # Initialize FAISS index\n",
        "    dimension = ipc_embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(ipc_embeddings.astype('float32'))  # Ensure ipc_embeddings are float32\n",
        "\n",
        "    # Calculate query embedding\n",
        "    query_embedding = calculate_weighted_query_embedding(roberta_output)\n",
        "\n",
        "    # Ensure the query_embedding has the same dimension as the FAISS index\n",
        "    assert query_embedding.shape[0] == dimension, f\"Dimension mismatch: query ({query_embedding.shape[0]}) vs index ({dimension})\"\n",
        "\n",
        "    # Search in FAISS index\n",
        "    k = 5  # Number of top results to retrieve\n",
        "    query_embedding = query_embedding.reshape(1, -1).astype('float32')  # Ensure query_embedding is float32\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Prepare and return top 3 results\n",
        "    top_results = []\n",
        "    for i, idx in enumerate(indices[0][:3]):  # Take only top 3 results\n",
        "        result = {\n",
        "            # \"distance\": distances[0][i],\n",
        "            \"text\": ipc_chunks[idx]\n",
        "        }\n",
        "        top_results.append(result)\n",
        "\n",
        "    return top_results\n",
        "\n",
        "\n",
        "\n",
        "def get_response_Law(query_keywords,Adversarial_Checked_query):\n",
        "    start = time.time()\n",
        "\n",
        "    top_results = process_ipc(query_keywords)\n",
        "    top_results_string = list_of_dicts_to_string(top_results)\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": f\"You are a Legal Chatbot - LawGPT, use the input as reference, paraphrase the input if correct and give a response adding other useful information missing in the input. Under no circumstances mention that the query is generated by you, Simply answer the questions, if its irrelated to the law context, answer it like a normal chatbot.Also format all the outputs correctly with no bold,etc Use these gathered law corpus as reference : {top_results_string}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{Adversarial_Checked_query}\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\",\n",
        "    )\n",
        "    end = time.time()\n",
        "    # print(\"Time taken:\",end-start,\"secs\")\n",
        "    groq_reponse = chat_completion.choices[0].message.content\n",
        "    return groq_reponse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAQTz0Ww9wUs",
        "outputId": "7205231a-484f-4c2c-e6f9-5634552dc27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help!\n",
            "\n",
            "The sections related to murder and attempt to murder under the Indian Penal Code (IPC) are as follows:\n",
            "\n",
            "* Murder: Section 302 of the IPC states that whoever commits murder shall be punished with death or imprisonment for life, and shall also be liable to fine.\n",
            "\n",
            "* Attempt to Murder: Section 307 of the IPC states that whoever attempts to commit murder shall be punished with imprisonment of either description for a term which may extend to ten years, and shall also be liable to fine.\n",
            "\n",
            "Additionally, it's worth noting that if the attempted murder is committed while committing or attempting to commit any of the offences specified in Section 397 of the IPC (such as robbery, dacoity, or lurking house-trespass), the punishment can be extended to imprisonment for life, or with rigorous imprisonment for a term which may extend to fourteen years.\n",
            "\n",
            "It's important to consult with a legal expert or law enforcement professional for specific guidance on a particular case, as the application of these sections can be fact-specific and nuanced.\n"
          ]
        }
      ],
      "source": [
        "# Query_output = get_response(NLP_Keywords)\n",
        "# # print(Query_output)\n",
        "NLP_Keywords = [('home', 0.4764), ('working', 0.4574), ('productive', 0.3846), ('tips', 0.3822), ('staying', 0.3181)]\n",
        "Adversarial_Checked_query = \"Could you please inform me about the specific section of the (IPC) under which an individual could be charged for murder, or attempt to murder\"\n",
        "\n",
        "Output = get_response_Law(NLP_Keywords,Adversarial_Checked_query)\n",
        "print(Output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq0uA35HumZv"
      },
      "source": [
        "# **General Context LLM**\n",
        "Currently using Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nz0OtcErusEf"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from groq import Groq\n",
        "\n",
        "# Initialize the Groq client with your API key\n",
        "client = Groq(\n",
        "    api_key='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',\n",
        ")\n",
        "\n",
        "# Function to get the response for a general query\n",
        "def get_response_General(query_input,global_sentiment_score,Adversarial_Checked_query):\n",
        "    start = time.time()\n",
        "\n",
        "    # Send the input query directly to the Groq API\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"You are a friendly and helpful chatbot. Your task is to answer all questions asked of you in a straightforward and Respectfull manner. If the sentiment of the user's input is low (as determined by a sentiment score between 0 and 1), respond with extra consideration and empathy. Provide support and understanding in your replies, aiming to uplift the user and address their concerns with care. For all other inputs, continue to answer questions in a straightforward and informative manner : {global_sentiment_score}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{Adversarial_Checked_query}\",\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama3-70b-8192\",\n",
        "    )\n",
        "\n",
        "    end = time.time()\n",
        "    # print(\"Time taken:\", end - start, \"secs\")\n",
        "\n",
        "    # Retrieve and return the response from Groq\n",
        "    groq_response = chat_completion.choices[0].message.content\n",
        "    return groq_response\n",
        "\n",
        "# # Test the function with a sample input\n",
        "# General_Output = get_response_General(\"What are some good productivity tips?\")\n",
        "# print(General_Output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bXLuPQoQQJ3",
        "outputId": "bbb91e09-25b5-4f3e-b725-25a1a39707fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help!\n",
            "\n",
            "In the Indian Penal Code (IPC), the specific sections related to murder and attempt to murder are:\n",
            "\n",
            "**Section 302: Murder**\n",
            "\n",
            "* Whoever commits murder shall be punished with death, or imprisonment for life, and shall also be liable to fine.\n",
            "\n",
            "**Section 307: Attempt to murder**\n",
            "\n",
            "* Whoever does any act with such intention or knowledge, and under such circumstances that, if he by that act caused death, he would be guilty of murder, shall be punished with imprisonment of either description for a term which may extend to ten years, and shall also be liable to fine; and if hurt is caused to any person by such act, the offender shall be liable either to imprisonment for life, or to such punishment as is hereinbefore mentioned.\n",
            "\n",
            "In simpler terms, Section 302 deals with the actual act of murder, whereas Section 307 deals with attempts to commit murder, even if the attempt is unsuccessful.\n",
            "\n",
            "Please let me know if you have any further questions or need clarification on these sections!\n",
            "[('home', 0.4764), ('working', 0.4574), ('productive', 0.3846), ('tips', 0.3822), ('staying', 0.3181)]\n"
          ]
        }
      ],
      "source": [
        "General_Output = get_response_General(NLP_Keywords,global_sentiment_score,Adversarial_Checked_query)\n",
        "print(General_Output)\n",
        "print(NLP_Keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Hk5HXxvWqE"
      },
      "source": [
        "# **Encryption Part 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvjyI2t3vfae"
      },
      "outputs": [],
      "source": [
        "# Encrypt the query\n",
        "encrypted_query = encrypt_data(Query, key)\n",
        "print(encrypted_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m17mqYhyvbAf"
      },
      "outputs": [],
      "source": [
        "# Decrypt the query\n",
        "decrypted_query = decrypt_data(encrypted_query, key)\n",
        "print(decrypted_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQmFxlKDtfLb"
      },
      "source": [
        "# **Hosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4LWVQWmptiGL",
        "outputId": "55faff3e-5fe3-4ef0-d728-31ba5c60e457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMxaVjNBtiv1",
        "outputId": "82088332-ae76-47cd-d83c-8efcbde99576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel:  NgrokTunnel: \"https://9da8-34-83-104-0.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:01:25] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:01:25] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:01:26] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:01:33] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:01:33] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:02:15] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:02:15] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set ngrok authtoken\n",
        "ngrok.set_auth_token(\"2lVyfZ9K1OoCqvIhUdFGCf9CADp_7FMRjdUHMDtGztzJJXu2d\")\n",
        "\n",
        "# Placeholder HTML template\n",
        "html_template = '''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>LawGPT Version Alpha</title>\n",
        "    <style>\n",
        "        body { margin: 0; padding: 0; font-family: 'Arial', sans-serif; background-color: #0A0A23; color: #ffffff; }\n",
        "        .container { display: flex; height: 100vh; }\n",
        "        .sidebar { width: 20%; background-color: #141432; padding: 20px; box-shadow: 2px 0 5px rgba(0, 0, 0, 0.5); display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .logo { margin-bottom: 30px; }\n",
        "        .menu button { display: block; background: none; color: #ffffff; padding: 15px 10px; border: none; text-align: left; width: 100%; cursor: pointer; font-size: 16px; }\n",
        "        .menu button:hover { background-color: #1E1E2D; }\n",
        "        .footer button { background: none; color: #ffffff; border: none; cursor: pointer; margin: 5px 0; font-size: 14px; }\n",
        "        .main { width: 80%; padding: 20px; display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .header { display: flex; justify-content: space-between; align-items: center; }\n",
        "        .chat-window { flex-grow: 1; background-color: #0F0F1F; padding: 20px; margin: 20px 0; border-radius: 10px; overflow-y: auto; position: relative; }\n",
        "        .chat-message { margin-bottom: 20px; }\n",
        "        .user-query { font-weight: bold; }\n",
        "        .chat-response p { margin: 5px 0; line-height: 1.5; }\n",
        "        .link { color: #E94560; text-decoration: none; }\n",
        "        .input-area { display: flex; align-items: center; }\n",
        "        .input-area input { width: 90%; padding: 10px; border-radius: 5px; border: 1px solid #3E3E5A; background-color: #0F0F1F; color: #ffffff; margin-right: 10px; }\n",
        "        .input-area button { background-color: #E94560; color: #ffffff; padding: 10px 20px; border: none; cursor: pointer; border-radius: 5px; }\n",
        "        .output-status { color: #E94560; font-weight: bold; position: absolute; bottom: 10px; right: 20px; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"sidebar\">\n",
        "            <div>\n",
        "                <div class=\"logo\">\n",
        "                    <img src=\"{{ url_for('static', filename='image.png') }}\" alt=\"Logo\" width=\"100\">\n",
        "                </div>\n",
        "                <div class=\"menu\">\n",
        "                    <button>Dashboard</button>\n",
        "                    <button>Download Chat</button>\n",
        "                    <button>All Chats</button>\n",
        "                    <button>Legal Documents</button>\n",
        "                    <button>Legal Consultancy</button>\n",
        "                    <button>Notification</button>\n",
        "                    <button>Clear conversations</button>\n",
        "                    <button>Light mode</button>\n",
        "                    <button>My account</button>\n",
        "                    <button>Updates & FAQ</button>\n",
        "                    <button>Log out</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <footer>\n",
        "                <button>Home</button>\n",
        "                <button>Services</button>\n",
        "                <button>About</button>\n",
        "            </footer>\n",
        "        </div>\n",
        "        <div class=\"main\">\n",
        "            <div class=\"header\">\n",
        "                <span class=\"model\">Model: All-MiniLM LawGPT</span>\n",
        "            </div>\n",
        "            <div class=\"chat-window\">\n",
        "                {% if query %}\n",
        "                <div class=\"chat-message user-query\">\n",
        "                    <p>{{ query }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                {% if processing_message %}\n",
        "                <div class=\"chat-message\">\n",
        "                    <p>{{ processing_message }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                {% if result %}\n",
        "                <div class=\"chat-message chat-response\">\n",
        "                    <p>{{ result }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                <div class=\"output-status\">{{ status }}</div>\n",
        "            </div>\n",
        "            <div class=\"input-area\">\n",
        "                <form method=\"post\">\n",
        "                    <input type=\"text\" id=\"query\" name=\"query\" placeholder=\"Enter your query here\" style=\"width: 1075px; height: 30px;\">\n",
        "                    <button type=\"submit\">Send</button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# def GeneralOrLegal_LLM(Query_Classification,Adversarial_Checked_query,global_sentiment_score,NLP_Keywords):\n",
        "#     if Query_Classification == 1:\n",
        "#         Law_GPT_Response = get_response_Law(NLP_Keywords,Adversarial_Checked_query)\n",
        "#         return Law_GPT_Response\n",
        "#     else:\n",
        "#         General_Response = get_response_General(NLP_Keywords, global_sentiment_score, Adversarial_Checked_query)\n",
        "#         return General_Response\n",
        "\n",
        "def Final_Function(user_input):\n",
        "    # Defining key\n",
        "    # Key-generation\n",
        "    password = \"SecureAIChatbot\"\n",
        "    salt = os.urandom(16)\n",
        "    key = generate_key(password, salt)\n",
        "\n",
        "    # Encrypting the user_input\n",
        "    encrypted_query = encrypt_data(user_input, key)\n",
        "\n",
        "    # Decrypt the query\n",
        "    decrypted_query = decrypt_data(encrypted_query, key)\n",
        "\n",
        "    # Push it for adversarial check\n",
        "    Adversarial_Checked_query = detect_adversarial_attack(decrypted_query)\n",
        "\n",
        "    # NLP Classification\n",
        "    Query_Classification = int(classify_text(Adversarial_Checked_query))\n",
        "\n",
        "    # # Content Filtering\n",
        "    Content_filtered_Query = filter_content(Query_Classification, Adversarial_Checked_query)\n",
        "\n",
        "    # # NLP Keywords\n",
        "    NLP_Keywords = process_query(Content_filtered_Query)\n",
        "\n",
        "    # # Determine if it should be processed by LawGPT or General LLM\n",
        "    # if Query_Classification == 1:\n",
        "\n",
        "    #     Output = get_response_Law(NLP_Keywords, Adversarial_Checked_query)\n",
        "    #     return processing_message, Output\n",
        "    # # else:\n",
        "    #     # processing_message = \"Processed by General LLM\"\n",
        "    #     # Output = get_response_General(NLP_Keywords, global_sentiment_score, Adversarial_Checked_query)\n",
        "    #     # return processing_message, Output\n",
        "\n",
        "    if Query_Classification == 1:\n",
        "        processing_message = \"Processed by LawGPT\"\n",
        "        Law_GPT_Response = get_response_Law(NLP_Keywords,Adversarial_Checked_query)\n",
        "        return Law_GPT_Response,processing_message\n",
        "    elif Query_Classification == 0:\n",
        "        processing_message = \"Processed by General LLM\"\n",
        "        General_Response = get_response_General(NLP_Keywords,global_sentiment_score,Adversarial_Checked_query)\n",
        "        return General_Response,processing_message\n",
        "    else:\n",
        "\n",
        "        return \"Error: Invalid Query Classification\"\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def backend_getter():\n",
        "    result = None\n",
        "    query_input = None\n",
        "    processing_message = \"\"\n",
        "    status = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        query_input = request.form['query']\n",
        "        if query_input:\n",
        "            # Call Final_Function with the user query\n",
        "            processing_message, result = Final_Function(query_input)\n",
        "        else:\n",
        "            status = \"Please enter a query.\"\n",
        "\n",
        "    return render_template_string(html_template, result=result, query=query_input, status=status, processing_message=processing_message)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Setup Ngrok tunnel\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(\" * ngrok tunnel: \", public_url)\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(port=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yd9ho48tk1-"
      },
      "outputs": [],
      "source": [
        "def Final_Function(user_input):\n",
        "\n",
        "  Query = user_input\n",
        "  #Encrypting the user_input\n",
        "  encrypted_query = encrypt_data(Query, key)\n",
        "  print(encrypted_query)\n",
        "\n",
        "  # Decrypt the query\n",
        "  decrypted_query = decrypt_data(encrypted_query, key)\n",
        "  print(decrypted_query)\n",
        "\n",
        "  # Push it for adversial check\n",
        "  Adversarial_Checked_query = detect_adversarial_attack(decrypted_query)\n",
        "  print(Adversarial_Checked_query)\n",
        "\n",
        "  #NLP Classification\n",
        "  Query_Classification = int(classify_text(Adversarial_Checked_query))\n",
        "  print(Query_Classification)\n",
        "\n",
        "  #Content Filtering\n",
        "  Content_filtered_Query = filter_content(Query_Classification, Adversarial_Checked_query)\n",
        "  print(Content_filtered_Query)\n",
        "\n",
        "  #NLP Keywords\n",
        "  NLP_Keywords = process_query(Content_filtered_Query)\n",
        "  print(NLP_Keywords)\n",
        "\n",
        "  if Query_Classification == 1:\n",
        "        print(\"Law_GPT_Response\")\n",
        "        Law_GPT_Response = get_response_Law(NLP_Keywords,Adversarial_Checked_query)\n",
        "        return Law_GPT_Response\n",
        "  else:\n",
        "        print(\"General GPT Response\")\n",
        "        General_Response = get_response_General(NLP_Keywords,global_sentiment_score,Adversarial_Checked_query)\n",
        "        return General_Response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb5oJG7Svdzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec804c2-ca45-4173-ad68-f67a6b6107f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N5yuUC4ZXpbwrrNcUqG/8UYXiTwQohe6SXe1Th6PWUaigtMeABerR9XOq4Xdlo50abo/eccR85214h0LrC08ff9c/KpQ9Gf97uh3AgX/ja1Y7yY8G0VckFa/zHNjjPJJcZ8rl/9TkBT9voP4+U6Oz4Q4TStERZ8SeQTNojRgXAM=\n",
            "Under what section of ipc does Hit and Run come, and what are the punishments for the same?\n",
            "Under what section of ipc does Hit and Run come, and what are the punishments for the same?\n",
            "1\n",
            "Under what section of ipc does Hit and Run come, and what are the punishments for the same?\n",
            "[('punishments', 0.5766), ('hit', 0.4665), ('run', 0.4458), ('ipc', 0.4218), ('come', 0.4023)]\n",
            "Law_GPT_Response\n",
            "The Hit and Run case is dealt under Section 304A of the Indian Penal Code (IPC).\n",
            "\n",
            "Section 304A of IPC states: \"Causing death by negligence - Whoever causes the death of any person by doing any rash or negligent act not amounting to culpable homicide, shall be punished with imprisonment of either description for a term which may extend to two years, or with fine, or with both.\"\n",
            "\n",
            "So, the punishment for Hit and Run under Section 304A of IPC is:\n",
            "\n",
            "* Imprisonment for a term which may extend to two years\n",
            "* Fine\n",
            "* Both imprisonment and fine\n",
            "\n",
            "Additionally, if the accident involves a motor vehicle, the Motor Vehicles Act, 1988, also comes into play. Section 187 of the Motor Vehicles Act deals with the Hit and Run cases. According to this section, if a person is involved in a hit and run accident, they can be punished with imprisonment for a term which may extend to six months, or with a fine which may extend to five thousand rupees, or with both.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Under what section of ipc does Hit and Run come, and what are the punishments for the same?\"\n",
        "output = Final_Function(user_input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYrGny7OAKIr"
      },
      "source": [
        "# **Original Hosting Code for backup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VjsPnb49uwT",
        "outputId": "44b2cb22-9781-4b0c-ab98-77d6e4ca663c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel:  NgrokTunnel: \"https://ccb2-34-82-102-102.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 07:45:04] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 07:45:05] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 07:45:05] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 07:45:12] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 07:45:13] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set ngrok authtoken\n",
        "ngrok.set_auth_token(\"2lVyfZ9K1OoCqvIhUdFGCf9CADp_7FMRjdUHMDtGztzJJXu2d\")\n",
        "\n",
        "# Placeholder HTML template\n",
        "html_template = '''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>LawGPT Version Alpha</title>\n",
        "    <style>\n",
        "        body { margin: 0; padding: 0; font-family: 'Arial', sans-serif; background-color: #0A0A23; color: #ffffff; }\n",
        "        .container { display: flex; height: 100vh; }\n",
        "        .sidebar { width: 20%; background-color: #141432; padding: 20px; box-shadow: 2px 0 5px rgba(0, 0, 0, 0.5); display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .logo { margin-bottom: 30px; }\n",
        "        .menu button { display: block; background: none; color: #ffffff; padding: 15px 10px; border: none; text-align: left; width: 100%; cursor: pointer; font-size: 16px; }\n",
        "        .menu button:hover { background-color: #1E1E2D; }\n",
        "        .footer button { background: none; color: #ffffff; border: none; cursor: pointer; margin: 5px 0; font-size: 14px; }\n",
        "        .main { width: 80%; padding: 20px; display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .header { display: flex; justify-content: space-between; align-items: center; }\n",
        "        .chat-window { flex-grow: 1; background-color: #0F0F1F; padding: 20px; margin: 20px 0; border-radius: 10px; overflow-y: auto; position: relative; }\n",
        "        .chat-message { margin-bottom: 20px; }\n",
        "        .user-query { font-weight: bold; }\n",
        "        .chat-response p { margin: 5px 0; line-height: 1.5; }\n",
        "        .link { color: #E94560; text-decoration: none; }\n",
        "        .input-area { display: flex; align-items: center; }\n",
        "        .input-area input { width: 90%; padding: 10px; border-radius: 5px; border: 1px solid #3E3E5A; background-color: #0F0F1F; color: #ffffff; margin-right: 10px; }\n",
        "        .input-area button { background-color: #E94560; color: #ffffff; padding: 10px 20px; border: none; cursor: pointer; border-radius: 5px; }\n",
        "        .output-status { color: #E94560; font-weight: bold; position: absolute; bottom: 10px; right: 20px; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"sidebar\">\n",
        "            <div>\n",
        "                <div class=\"logo\">\n",
        "                    <img src=\"{{ url_for('static', filename='image.png') }}\" alt=\"Logo\" width=\"100\">\n",
        "                </div>\n",
        "                <div class=\"menu\">\n",
        "                    <button>Dashboard</button>\n",
        "                    <button>Download Chat</button>\n",
        "                    <button>All Chats</button>\n",
        "                    <button>Legal Documents</button>\n",
        "                    <button>Legal Consultancy</button>\n",
        "                    <button>Notification</button>\n",
        "                    <button>Clear conversations</button>\n",
        "                    <button>Light mode</button>\n",
        "                    <button>My account</button>\n",
        "                    <button>Updates & FAQ</button>\n",
        "                    <button>Log out</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <footer>\n",
        "                <button>Home</button>\n",
        "                <button>Services</button>\n",
        "                <button>About</button>\n",
        "            </footer>\n",
        "        </div>\n",
        "        <div class=\"main\">\n",
        "            <div class=\"header\">\n",
        "                <span class=\"model\">Model: All-MiniLM LawGPT</span>\n",
        "            </div>\n",
        "            <div class=\"chat-window\">\n",
        "                {% if query %}\n",
        "                <div class=\"chat-message user-query\">\n",
        "                    <p>{{ query }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                {% if result %}\n",
        "                <div class=\"chat-message chat-response\">\n",
        "                    <p>{{ result }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                <div class=\"output-status\">{{ status }}</div>\n",
        "            </div>\n",
        "            <div class=\"input-area\">\n",
        "                <form method=\"post\">\n",
        "                    <input type=\"text\" id=\"query\" name=\"query\" placeholder=\"Enter your query here\" style=\"width: 1075px; height: 30px;\">\n",
        "                    <button type=\"submit\">Send</button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>'''\n",
        "\n",
        "\n",
        "def Final_Function(user_input):\n",
        "    # Defining key\n",
        "    #Key- generation\n",
        "    password = \"SecureAIChatbot\"\n",
        "    salt = os.urandom(16)\n",
        "    key = generate_key(password, salt)\n",
        "\n",
        "    # Encrypting the user_input\n",
        "    encrypted_query = encrypt_data(user_input, key)\n",
        "\n",
        "    # Decrypt the query\n",
        "    decrypted_query = decrypt_data(encrypted_query, key)\n",
        "\n",
        "    # Push it for adversarial check\n",
        "    Adversarial_Checked_query = detect_adversarial_attack(decrypted_query)\n",
        "\n",
        "    # NLP Classification\n",
        "    Query_Classification = classify_text(Adversarial_Checked_query)\n",
        "\n",
        "    # Content Filtering\n",
        "    Content_filtered_Query = filter_content(Query_Classification, Adversarial_Checked_query)\n",
        "\n",
        "    # NLP Keywords\n",
        "    NLP_Keywords = process_query(Content_filtered_Query)\n",
        "\n",
        "    if Query_Classification == 1:\n",
        "        Law_GPT_Response = get_response_Law(NLP_Keywords,Adversarial_Checked_query)\n",
        "        return Law_GPT_Response\n",
        "    elif Query_Classification == 0:\n",
        "        General_Response = get_response_General(NLP_Keywords, global_sentiment_score, Adversarial_Checked_query)\n",
        "        return General_Response\n",
        "    else: return \"Error: Invalid Query Classification\"\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def backend_getter():\n",
        "    result = None\n",
        "    query_input = None\n",
        "    status = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        query_input = request.form['query']\n",
        "        if query_input:\n",
        "            # Call Final_Function with the user query\n",
        "            result = Final_Function(query_input)\n",
        "            # print(result)\n",
        "        else:\n",
        "            status = \"Please enter a query.\"\n",
        "\n",
        "    return render_template_string(html_template, result=result, query=query_input, status=status)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Setup Ngrok tunnel\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(\" * ngrok tunnel: \", public_url)\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Toggle Update**"
      ],
      "metadata": {
        "id": "e0udWjCcsm7d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vYWQY6U2Iadt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92acbbba-708f-4ca4-cb88-f3054cddf8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel:  NgrokTunnel: \"https://9eb9-34-83-104-0.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:02:59] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:00] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:00] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:07] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:08] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:52] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:03:52] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:04:24] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:04:25] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:04:49] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Sep/2024 19:04:49] \"\u001b[33mGET /static/image.png HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set ngrok authtoken\n",
        "ngrok.set_auth_token(\"2lVyfZ9K1OoCqvIhUdFGCf9CADp_7FMRjdUHMDtGztzJJXu2d\")\n",
        "\n",
        "# Placeholder HTML template\n",
        "html_template = '''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>LawGPT Version Alpha</title>\n",
        "    <style>\n",
        "        body { margin: 0; padding: 0; font-family: 'Arial', sans-serif; background-color: #0A0A23; color: #ffffff; }\n",
        "        .container { display: flex; height: 100vh; }\n",
        "        .sidebar { width: 20%; background-color: #141432; padding: 20px; box-shadow: 2px 0 5px rgba(0, 0, 0, 0.5); display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .logo { margin-bottom: 30px; }\n",
        "        .menu button { display: block; background: none; color: #ffffff; padding: 15px 10px; border: none; text-align: left; width: 100%; cursor: pointer; font-size: 16px; }\n",
        "        .menu button:hover { background-color: #1E1E2D; }\n",
        "        .footer button { background: none; color: #ffffff; border: none; cursor: pointer; margin: 5px 0; font-size: 14px; }\n",
        "        .main { width: 80%; padding: 20px; display: flex; flex-direction: column; justify-content: space-between; }\n",
        "        .header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; }\n",
        "        .chat-window { flex-grow: 1; background-color: #0F0F1F; padding: 20px; margin: 20px 0; border-radius: 10px; overflow-y: auto; position: relative; }\n",
        "        .chat-message { margin-bottom: 20px; }\n",
        "        .user-query { font-weight: bold; }\n",
        "        .chat-response p { margin: 5px 0; line-height: 1.5; }\n",
        "        .link { color: #E94560; text-decoration: none; }\n",
        "        .input-area { display: flex; align-items: center; }\n",
        "        .input-area input { flex-grow: 1; padding: 10px; border-radius: 5px; border: 1px solid #3E3E5A; background-color: #0F0F1F; color: #ffffff; }\n",
        "        .input-area button { background-color: #E94560; color: #ffffff; padding: 10px 20px; border: none; cursor: pointer; border-radius: 5px; margin-left: 10px; }\n",
        "        .output-status { color: #E94560; font-weight: bold; position: absolute; bottom: 10px; right: 20px; }\n",
        "        .toggle-switch { display: flex; align-items: center; margin-bottom: 20px; }\n",
        "        .toggle-switch label { margin-right: 10px; color: #ffffff; }\n",
        "        .toggle-switch select { padding: 5px; border-radius: 5px; border: 1px solid #3E3E5A; background-color: #0F0F1F; color: #ffffff; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"sidebar\">\n",
        "            <div>\n",
        "                <div class=\"logo\">\n",
        "                    <img src=\"{{ url_for('static', filename='image.png') }}\" alt=\"Logo\" width=\"100\">\n",
        "                </div>\n",
        "                <div class=\"menu\">\n",
        "                    <button>Dashboard</button>\n",
        "                    <button>Download Chat</button>\n",
        "                    <button>All Chats</button>\n",
        "                    <button>Legal Documents</button>\n",
        "                    <button>Legal Consultancy</button>\n",
        "                    <button>Notification</button>\n",
        "                    <button>Clear conversations</button>\n",
        "                    <button>Light mode</button>\n",
        "                    <button>My account</button>\n",
        "                    <button>Updates & FAQ</button>\n",
        "                    <button>Log out</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <footer>\n",
        "                <button>Home</button>\n",
        "                <button>Services</button>\n",
        "                <button>About</button>\n",
        "            </footer>\n",
        "        </div>\n",
        "        <div class=\"main\">\n",
        "            <div class=\"header\">\n",
        "                <span class=\"model\">Model: Secure</span>\n",
        "            </div>\n",
        "            <div class=\"toggle-switch\">\n",
        "                <label for=\"mode\">Choose Mode:</label>\n",
        "                <select id=\"mode\" name=\"mode\" form=\"queryForm\">\n",
        "                    <option value=\"neutral\">Neutral</option>\n",
        "                    <option value=\"legal\">Legal</option>\n",
        "                    <option value=\"general\">General</option>\n",
        "                </select>\n",
        "            </div>\n",
        "            <div class=\"chat-window\">\n",
        "                {% if query %}\n",
        "                <div class=\"chat-message user-query\">\n",
        "                    <p>{{ query }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                {% if processing_message %}\n",
        "                <div class=\"chat-message\">\n",
        "                    <p>{{ processing_message }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                {% if result %}\n",
        "                <div class=\"chat-message chat-response\">\n",
        "                    <p>{{ result }}</p>\n",
        "                </div>\n",
        "                {% endif %}\n",
        "                <div class=\"output-status\">{{ status }}</div>\n",
        "            </div>\n",
        "            <div class=\"input-area\">\n",
        "                <form method=\"post\" id=\"queryForm\">\n",
        "                    <input type=\"text\" id=\"query\" name=\"query\" placeholder=\"Enter your query here\">\n",
        "                    <button type=\"submit\">Send</button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "def Final_Function(user_input, mode):\n",
        "    # Defining key\n",
        "    password = \"SecureAIChatbot\"\n",
        "    salt = os.urandom(16)\n",
        "    key = generate_key(password, salt)\n",
        "\n",
        "    # Encrypting the user_input\n",
        "    encrypted_query = encrypt_data(user_input, key)\n",
        "\n",
        "    # Decrypt the query\n",
        "    decrypted_query = decrypt_data(encrypted_query, key)\n",
        "\n",
        "    # Push it for adversarial check\n",
        "    Adversarial_Checked_query = detect_adversarial_attack(decrypted_query)\n",
        "\n",
        "    # Determine the Query Classification based on the selected mode\n",
        "    if mode == \"legal\":\n",
        "        Query_Classification = 1\n",
        "    elif mode == \"general\":\n",
        "        Query_Classification = 0\n",
        "    else:  # Neutral mode, perform normal classification\n",
        "        Query_Classification = int(classify_text(Adversarial_Checked_query))\n",
        "\n",
        "    # Content Filtering\n",
        "    Content_filtered_Query = filter_content(Query_Classification, Adversarial_Checked_query)\n",
        "\n",
        "    # NLP Keywords\n",
        "    NLP_Keywords = process_query(Content_filtered_Query)\n",
        "\n",
        "    # Determine if it should be processed by LawGPT or General LLM\n",
        "    if Query_Classification == 1:\n",
        "        processing_message = \"Processed by LawGPT\"\n",
        "        Output = get_response_Law(NLP_Keywords, Adversarial_Checked_query)\n",
        "    else:\n",
        "        processing_message = \"Processed by General LLM\"\n",
        "        Output = get_response_General(NLP_Keywords, global_sentiment_score, Adversarial_Checked_query)\n",
        "\n",
        "    return processing_message, Output\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def backend_getter():\n",
        "    result = None\n",
        "    query_input = None\n",
        "    processing_message = \"\"\n",
        "    status = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        query_input = request.form['query']\n",
        "        mode = request.form['mode']\n",
        "        if query_input:\n",
        "            processing_message, result = Final_Function(query_input, mode)\n",
        "        else:\n",
        "            status = \"Please enter a query.\"\n",
        "\n",
        "    return render_template_string(html_template, result=result, query=query_input, status=status, processing_message=processing_message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Setup Ngrok tunnel\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(\" * ngrok tunnel: \", public_url)\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PDF Update**"
      ],
      "metadata": {
        "id": "yR8R45IFtnRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "0ZXpS5NnsuY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2090441f-fd22-4c8f-f2cf-adecd7b81a24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.42.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.113.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.6)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.38.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3061, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info. Did you mean: 'egg_info'?\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3081, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3064, in _parsed_pkg_info\n",
            "    self._pkg_info = email.parser.Parser().parsestr(metadata)\n",
            "  File \"/usr/lib/python3.10/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "  File \"/usr/lib/python3.10/email/parser.py\", line 49, in parse\n",
            "    feedparser = FeedParser(self._class, policy=self.policy)\n",
            "  File \"/usr/lib/python3.10/email/feedparser.py\", line 162, in __init__\n",
            "    self._input = BufferedSubFile()\n",
            "  File \"/usr/lib/python3.10/email/feedparser.py\", line 53, in __init__\n",
            "    def __init__(self):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Function to handle chatbot responses\n",
        "def chatbot_response(message, state):\n",
        "    # Placeholder response; replace with your actual processing logic\n",
        "    response = f\"Processing: {message}\"\n",
        "    state.append((\"User\", message))\n",
        "    state.append((\"Bot\", response))\n",
        "    return state, state\n",
        "\n",
        "# Function to handle file upload\n",
        "def handle_file_upload(file):\n",
        "    # File handling logic (placeholder response)\n",
        "    return f\"File {file.name} uploaded successfully. You can start chatting.\"\n",
        "\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #1f1f1f; padding: 20px;}\") as demo:\n",
        "    # Header section for styling and introduction\n",
        "    gr.Markdown(\"<h1 style='text-align: center; color: #e0e0e0;'>Dark Theme Chatbot Interface with PDF Upload</h1>\")\n",
        "\n",
        "    # File upload section at the top\n",
        "    with gr.Row():\n",
        "        upload_input = gr.File(label=\"Upload your PDF file\", type=\"filepath\", file_count=\"single\", elem_id=\"upload-box\")\n",
        "\n",
        "    # Chatbot section\n",
        "    with gr.Column(elem_id=\"chatbot-container\"):\n",
        "        chatbot = gr.Chatbot(label=\"\", elem_id=\"chatbot\")\n",
        "\n",
        "        with gr.Row(elem_id=\"input-row\"):\n",
        "            user_input = gr.Textbox(placeholder=\"Type your message here...\", show_label=False, elem_id=\"input-box\")\n",
        "            submit_button = gr.Button(\"Send\", elem_id=\"send-button\")\n",
        "\n",
        "        state = gr.State([])  # To store conversation history\n",
        "\n",
        "    # Define action to process user message in chatbot mode\n",
        "    submit_button.click(fn=chatbot_response, inputs=[user_input, state], outputs=[chatbot, state])\n",
        "\n",
        "    # Connect the upload action to display file upload status\n",
        "    upload_input.change(fn=handle_file_upload, inputs=upload_input, outputs=[])\n",
        "\n",
        "# CSS for dark theme styling\n",
        "demo.css = \"\"\"\n",
        "#upload-box {\n",
        "    margin-bottom: 20px;\n",
        "    padding: 5px;\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 5px;\n",
        "    background-color: #2a2e35;\n",
        "    color: #e0e0e0;\n",
        "    width: 100%;\n",
        "    height: 40px;  /* Reduced height for a sleeker look */\n",
        "}\n",
        "\n",
        "#chatbot-container {\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    background: #2a2e35;\n",
        "    max-height: 500px;\n",
        "    overflow-y: auto;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message {\n",
        "    padding: 10px;\n",
        "    border-radius: 10px;\n",
        "    margin: 5px;\n",
        "    max-width: 75%;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message.user {\n",
        "    background-color: #3b3f46;\n",
        "    align-self: flex-end;\n",
        "    text-align: right;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message.bot {\n",
        "    background-color: #33373e;\n",
        "    align-self: flex-start;\n",
        "    text-align: left;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#input-row {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 10px;  /* Space between textbox and button */\n",
        "}\n",
        "\n",
        "#input-box {\n",
        "    flex: 8;  /* 8 parts of the width */\n",
        "    padding: 10px;\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 5px;\n",
        "    background-color: #2a2e35;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#send-button {\n",
        "    flex: 1;  /* 1 part of the width */\n",
        "    padding: 10px 20px;\n",
        "    background-color: #4a90e2;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 5px;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "#send-button:hover {\n",
        "    background-color: #357ab8;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "07PsTUdPFxzR",
        "outputId": "1fe9d089-584e-490b-8d11-baf6b55ec846"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d707e599874a7d96c5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d707e599874a7d96c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "# Define a directory to save uploaded files\n",
        "UPLOAD_DIR = \"uploads\"\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# Path to save the uploaded file\n",
        "SAVED_FILE_PATH = os.path.join(UPLOAD_DIR, \"UserInput.pdf\")\n",
        "\n",
        "# Function to handle chatbot responses\n",
        "def chatbot_response(message, state):\n",
        "    # Placeholder response; replace with your actual processing logic\n",
        "    response = f\"Processing: {message}\"\n",
        "    state.append((\"User\", message))\n",
        "    state.append((\"Bot\", response))\n",
        "    return state, state\n",
        "\n",
        "# Function to handle file upload and save the file\n",
        "def handle_file_upload(file):\n",
        "    if file is not None:\n",
        "        # Save the file to the specified directory\n",
        "        with open(SAVED_FILE_PATH, \"wb\") as f:\n",
        "            f.write(file.read())\n",
        "        return f\"File saved as {SAVED_FILE_PATH}. You can start chatting.\"\n",
        "    return \"No file uploaded.\"\n",
        "\n",
        "# Function to delete the saved file\n",
        "def delete_file():\n",
        "    if os.path.exists(SAVED_FILE_PATH):\n",
        "        os.remove(SAVED_FILE_PATH)\n",
        "        return \"File deleted successfully.\"\n",
        "    return \"No file to delete.\"\n",
        "\n",
        "# Function to handle cancellation\n",
        "def cancel_upload():\n",
        "    return delete_file()\n",
        "\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #1f1f1f; padding: 20px;}\") as demo:\n",
        "    # Header section for styling and introduction\n",
        "    gr.Markdown(\"<h1 style='text-align: center; color: #e0e0e0;'>Dark Theme Chatbot Interface with PDF Upload</h1>\")\n",
        "\n",
        "    # File upload section at the top\n",
        "    with gr.Row():\n",
        "        upload_input = gr.File(label=\"Upload your PDF file\", type=\"binary\", file_count=\"single\", elem_id=\"upload-box\")\n",
        "\n",
        "    # Chatbot section\n",
        "    with gr.Column(elem_id=\"chatbot-container\"):\n",
        "        chatbot = gr.Chatbot(label=\"\", elem_id=\"chatbot\")\n",
        "\n",
        "        with gr.Row(elem_id=\"input-row\"):\n",
        "            user_input = gr.Textbox(placeholder=\"Type your message here...\", show_label=False, elem_id=\"input-box\")\n",
        "            submit_button = gr.Button(\"Send\", elem_id=\"send-button\")\n",
        "\n",
        "        state = gr.State([])  # To store conversation history\n",
        "\n",
        "    # Define action to process user message in chatbot mode\n",
        "    submit_button.click(fn=chatbot_response, inputs=[user_input, state], outputs=[chatbot, state])\n",
        "\n",
        "    # Connect the upload action to save the file and display status\n",
        "    upload_input.change(fn=handle_file_upload, inputs=upload_input, outputs=[])\n",
        "\n",
        "    # Define a button to cancel and delete the file\n",
        "    cancel_button = gr.Button(\"Cancel Upload\", elem_id=\"cancel-button\")\n",
        "    cancel_button.click(fn=cancel_upload, outputs=[])\n",
        "\n",
        "# CSS for dark theme styling\n",
        "demo.css = \"\"\"\n",
        "#upload-box {\n",
        "    margin-bottom: 20px;\n",
        "    padding: 5px;\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 5px;\n",
        "    background-color: #2a2e35;\n",
        "    color: #e0e0e0;\n",
        "    width: 100%;\n",
        "    height: 40px;  /* Reduced height for a sleeker look */\n",
        "}\n",
        "\n",
        "#chatbot-container {\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    background: #2a2e35;\n",
        "    max-height: 500px;\n",
        "    overflow-y: auto;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message {\n",
        "    padding: 10px;\n",
        "    border-radius: 10px;\n",
        "    margin: 5px;\n",
        "    max-width: 75%;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message.user {\n",
        "    background-color: #3b3f46;\n",
        "    align-self: flex-end;\n",
        "    text-align: right;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#chatbot .gradio-chatbot-message.bot {\n",
        "    background-color: #33373e;\n",
        "    align-self: flex-start;\n",
        "    text-align: left;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#input-row {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 10px;  /* Space between textbox and button */\n",
        "}\n",
        "\n",
        "#input-box {\n",
        "    flex: 8;  /* 8 parts of the width */\n",
        "    padding: 10px;\n",
        "    border: 1px solid #3a3f47;\n",
        "    border-radius: 5px;\n",
        "    background-color: #2a2e35;\n",
        "    color: #e0e0e0;\n",
        "}\n",
        "\n",
        "#send-button {\n",
        "    flex: 1;  /* 1 part of the width */\n",
        "    padding: 10px 20px;\n",
        "    background-color: #4a90e2;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 5px;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "#send-button:hover {\n",
        "    background-color: #357ab8;\n",
        "}\n",
        "\n",
        "#cancel-button {\n",
        "    margin-top: 10px;\n",
        "    padding: 10px 20px;\n",
        "    background-color: #e94e77;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 5px;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "#cancel-button:hover {\n",
        "    background-color: #d23f60;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "43MzYJEYF66i",
        "outputId": "7255df74-a1bd-4371-caa6-53ec8a9691d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a0a6986e10750c4c64.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a0a6986e10750c4c64.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noj2p20yLuD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}